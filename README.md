Implements a ViViT-based model for video action classification.
Achieves 91% accuracy, demonstrating the potential of transformer-based architectures in video recognition.
Uses self-attention mechanisms to effectively process sequential frames.
Addresses challenges such as high computational demands and variability in video quality.
Future improvements required, work going on.
Applicable in action recognition, surveillance, and multimedia analysis.
